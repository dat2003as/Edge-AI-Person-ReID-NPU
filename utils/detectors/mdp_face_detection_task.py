import cv2
import numpy as np
import mediapipe as mp
import time
import os
from utils.dlib_aligner import FaceAligner

# --- Th∆∞ vi·ªán m·ªõi c·ªßa MediaPipe Tasks ---
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
# X√ìA B·ªé IMPORT C≈®, ch√∫ng ta kh√¥ng c·∫ßn n√≥ n·ªØa
# from mediapipe.framework.formats import detection_pb2

# TH√äM IMPORT M·ªöI: namedtuple ƒë·ªÉ t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng ƒë∆°n gi·∫£n
from collections import namedtuple

# T·∫†O L·ªöP ƒê∆†N GI·∫¢N ƒê·ªÇ L∆ØU BBOX, thay th·∫ø cho ƒë·ªëi t∆∞·ª£ng ph·ª©c t·∫°p c·ªßa MediaPipe
# N√≥ c√≥ c√°c thu·ªôc t√≠nh y h·ªát nh∆∞ code c≈© c·∫ßn (.xmin, .ymin, .width, .height)
RelativeBoundingBox = namedtuple("RelativeBoundingBox", ["xmin", "ymin", "width", "height"])


class FaceDetection:
    """ 
    L·ªõp ph√°t hi·ªán khu√¥n m·∫∑t s·ª≠ d·ª•ng API MediaPipe Tasks m·ªõi n·∫°p t·ª´ RAM ƒë·ªÉ tr√°nh l·ªói ƒë∆∞·ªùng d·∫´n Windows.
    """
    def __init__(self,
                 model_name: str = "blaze_face_short_range.tflite",
                 min_detection_confidence: float = 0.4):
        
        # 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n file model (v·∫´n c·∫ßn ƒë·ªÉ Python t·ª± m·ªü file)
        model_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "models",
            model_name
        )

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file model t·∫°i: {model_path}")

        # --- üîπ B∆Ø·ªöC FIX CH√çNH: N·∫†P MODEL V√ÄO RAM üîπ ---
        try:
            # T·ª± m·ªü file b·∫±ng Python ƒë·ªÉ tr√°nh l·ªói MediaPipe n·ªëi chu·ªói site-packages
            with open(model_path, 'rb') as f:
                model_buffer = f.read()

            # S·ª≠ d·ª•ng model_asset_buffer thay v√¨ model_asset_path
            base_options = mp.tasks.BaseOptions(model_asset_buffer=model_buffer)
            
            options = vision.FaceDetectorOptions(
                base_options=base_options,
                running_mode=vision.RunningMode.IMAGE,
                min_detection_confidence=min_detection_confidence
            )
            
            # Kh·ªüi t·∫°o detector t·ª´ d·ªØ li·ªáu trong RAM
            self.detector = vision.FaceDetector.create_from_options(options)
            
            self.face_aligner = FaceAligner()
            self.fps_avg = 0.0
            self.call_count = 0
            print(f"‚úÖ FaceDetection (Buffer Mode) ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng.")
            print(f"FaceDetection (MediaPipe Tasks) ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng v·ªõi model: {model_name}")

        except Exception as e:
            print(f"‚ùå L·ªói khi n·∫°p Face Detector qua Buffer: {e}")
            raise

    def detect(self, image: np.ndarray):
        start_time = time.time()
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)
        detection_result = self.detector.detect(mp_image)

        detections_info = []
        raw_detections = []
        
        if detection_result.detections:
            img_h, img_w = image.shape[:2]
            for det in detection_result.detections:
                score = det.categories[0].score
                bbox_abs = det.bounding_box
                
                # S·ª¨A L·ªñI: D√πng ƒë·ªëi t∆∞·ª£ng RelativeBoundingBox ƒë∆°n gi·∫£n m√† ch√∫ng ta ƒë√£ t·∫°o
                bbox_rel = RelativeBoundingBox(
                    xmin=bbox_abs.origin_x / img_w,
                    ymin=bbox_abs.origin_y / img_h,
                    width=bbox_abs.width / img_w,
                    height=bbox_abs.height / img_h,
                )

                keypoints_rel = [(kp.x, kp.y) for kp in det.keypoints]
                info = {
                    'confidence': score,
                    'bbox': bbox_rel,
                    'keypoints': keypoints_rel
                }
                detections_info.append(info)
                raw_detections.append(det)

        end_time = time.time()
        duration = end_time - start_time
        self.call_count += 1
        
        return detections_info, raw_detections

    # ... c√°c h√†m c√≤n l·∫°i (close, detect_and_align) gi·ªØ nguy√™n kh√¥ng thay ƒë·ªïi ...
    def close(self):
        if self.detector:
            self.detector.close()
            print("T√†i nguy√™n c·ªßa FaceDetector ƒë√£ ƒë∆∞·ª£c gi·∫£i ph√≥ng.")

    def detect_and_align(self, image, margin: float = 0.3, padding: float = 0.2):
        infos, _ = self.detect(image)
        if not infos:
            return None
        bbox = infos[0]['bbox']
        h, w = image.shape[:2]
        x1 = max(0, int((bbox.xmin * w) - bbox.width * w * margin))
        y1 = max(0, int((bbox.ymin * h) - bbox.height * h * margin))
        x2 = min(w, int(x1 + bbox.width * w * (1 + 2 * margin)))
        y2 = min(h, int(y1 + bbox.height * h * (1 + 2 * margin)))
        roi = image[y1:y2, x1:x2]
        if roi.size == 0:
            return None
        return self.face_aligner.aligning(roi, padding=padding)