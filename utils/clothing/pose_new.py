#utils/pose_new.py
import os
import time
import asyncio
import cv2
import numpy as np
from sklearn.cluster import KMeans
from typing import Optional, List, Tuple, Dict, Any

# Gi·∫£ ƒë·ªãnh c√°c import n√†y ƒë√∫ng v·ªõi c·∫•u tr√∫c d·ª± √°n c·ªßa b·∫°n
from .clothing_new import ClothingClassifier
from utils.logging_python_orangepi import get_logger
from utils.detectors.mediapipe_pose import HumanDetection 

logger = get_logger(__name__)
# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c debug (t∆∞∆°ng ƒë·ªëi ho·∫∑c tuy·ªát ƒë·ªëi t√πy project)

class PoseColorAnalyzer:
    """
    [PHI√äN B·∫¢N T√ÅI C·∫§U TR√öC]
    - S·ª≠ d·ª•ng c√°c h√†m ti·ªán √≠ch t·ª´ HumanDetection ƒë·ªÉ x√°c ƒë·ªãnh v√πng c∆° th·ªÉ.
    - Ch·ªâ ph√¢n t√≠ch m√†u tr√™n c√°c chi "t·ªët nh·∫•t" (g·∫ßn camera nh·∫•t, r√µ nh·∫•t).
    - T·ªëi ∆∞u h√≥a logic, lo·∫°i b·ªè c√°c h·∫±ng s·ªë v√† c√°c h√†m tr√≠ch xu·∫•t d∆∞ th·ª´a.
    """
    
    # ƒê√£ lo·∫°i b·ªè c√°c h·∫±ng s·ªë ƒë·ªãnh nghƒ©a keypoint c≈©

    def __init__(self, line_thickness: int = 30, k_clusters: int = 3):
        self.line_thickness = line_thickness
        self.k_clusters = k_clusters
        self.MIN_PIXELS_FOR_COLOR = 50
        self.MIN_PERCENTAGE = 7.0
        self.MERGE_THRESHOLD = 50.0
        self.MONOCHROMATIC_THRESHOLD = 80.0
        self.fps = 0.0
        self.frame_count = 0
        self.start_time = asyncio.get_event_loop().time() if asyncio.get_event_loop().is_running() else 0.0

    def _is_valid_point(self, point) -> bool:
        """Ki·ªÉm tra ƒëi·ªÉm keypoint c√≥ h·ª£p l·ªá kh√¥ng."""
        return point is not None and len(point) >= 2 and point[0] != 0 and point[1] != 0

    def _get_pixels_from_polygon(self, image: np.ndarray, points: List[Tuple[int, int]]) -> Optional[np.ndarray]:
        """Tr√≠ch xu·∫•t pixels t·ª´ v√πng ƒëa gi√°c (d√πng cho torso)."""
        if len(points) < 3:
            return None
        try:
            h, w = image.shape[:2]
            mask = np.zeros((h, w), dtype=np.uint8)
            cv2.fillConvexPoly(mask, np.array(points, dtype=np.int32), 255)
            pixels = image[mask == 255]
            return pixels if len(pixels) >= self.MIN_PIXELS_FOR_COLOR else None
        except Exception as e:
            logger.debug(f"L·ªói tr√≠ch xu·∫•t pixels t·ª´ polygon: {e}")
            return None

    def _get_pixels_from_line(self, image: np.ndarray, start_point: tuple, end_point: tuple) -> Optional[np.ndarray]:
        """Tr√≠ch xu·∫•t pixels t·ª´ m·ªôt ƒë∆∞·ªùng th·∫≥ng c√≥ ƒë·ªô d√†y (d√πng cho tay, ch√¢n)."""
        try:
            mask = np.zeros(image.shape[:2], dtype=np.uint8)
            cv2.line(mask, start_point, end_point, 255, self.line_thickness)
            pixels = image[mask == 255]
            return pixels if len(pixels) >= 10 else None
        except Exception:
            return None

    def _calculate_color_distance_lab(self, color1_bgr: np.ndarray, color2_bgr: np.ndarray) -> float:
        """T√≠nh kho·∫£ng c√°ch m√†u trong kh√¥ng gian LAB ƒë·ªÉ so s√°nh m√†u s·∫Øc ch√≠nh x√°c h∆°n."""
        try:
            color1_lab = cv2.cvtColor(np.uint8([[color1_bgr]]), cv2.COLOR_BGR2LAB)[0][0]
            color2_lab = cv2.cvtColor(np.uint8([[color2_bgr]]), cv2.COLOR_BGR2LAB)[0][0]
            return np.linalg.norm(color1_lab.astype(float) - color2_lab.astype(float))
        except:
            return float('inf')

    def _merge_similar_colors(self, colors: List[np.ndarray], percentages: List[float]) -> Tuple[List[np.ndarray], List[float]]:
        """G·ªôp c√°c m√†u t∆∞∆°ng t·ª± trong b·∫£ng m√†u ƒë·ªÉ k·∫øt qu·∫£ g·ªçn h∆°n."""
        if len(colors) < 2:
            return colors, percentages
        merged_colors = colors.copy()
        merged_percentages = percentages.copy()
        i = 0
        while i < len(merged_colors):
            j = i + 1
            while j < len(merged_colors):
                distance = self._calculate_color_distance_lab(merged_colors[i], merged_colors[j])
                if distance < self.MERGE_THRESHOLD:
                    total_percentage = merged_percentages[i] + merged_percentages[j]
                    new_color = ((merged_colors[i] * merged_percentages[i] + merged_colors[j] * merged_percentages[j]) / total_percentage)
                    merged_colors[i] = new_color
                    merged_percentages[i] = total_percentage
                    merged_colors.pop(j)
                    merged_percentages.pop(j)
                    j -= 1
                j += 1
            i += 1
        return merged_colors, merged_percentages

    def analyze_colors_simple(self, pixels: np.ndarray) -> Optional[List[Dict]]:
        """Ph√¢n t√≠ch m√†u ƒë∆°n gi·∫£n - ch·ªâ l·∫•y m√†u trung b√¨nh."""
        if pixels is None or len(pixels) == 0:
            return None
        try:
            mean_color = np.mean(pixels, axis=0).astype(int)
            return [{"bgr": mean_color.tolist(), "percentage": 100.0}]
        except Exception as e:
            logger.debug(f"L·ªói ph√¢n t√≠ch m√†u ƒë∆°n gi·∫£n: {e}")
            return None

    def analyze_colors_advanced(self, pixels: np.ndarray) -> Optional[List[Dict]]:
        """Ph√¢n t√≠ch m√†u n√¢ng cao b·∫±ng K-Means ƒë·ªÉ tr√≠ch xu·∫•t b·∫£ng m√†u."""
        if pixels is None or len(pixels) < self.k_clusters:
            return self.analyze_colors_simple(pixels)
        try:
            pixels_rgb = cv2.cvtColor(np.uint8([pixels]), cv2.COLOR_BGR2RGB)[0]
            k = max(2, min(self.k_clusters, len(pixels) // 20 if len(pixels) >= 40 else 2))
            
            kmeans = KMeans(n_clusters=k, n_init=4, random_state=42)
            kmeans.fit(pixels_rgb)
            
            total_pixels = len(kmeans.labels_)
            counts = np.bincount(kmeans.labels_)
            colors_rgb = kmeans.cluster_centers_
            colors_bgr = cv2.cvtColor(np.uint8([colors_rgb]), cv2.COLOR_RGB2BGR)[0]
            
            valid_colors, valid_percentages = [], []
            for i, count in enumerate(counts):
                percentage = (count / total_pixels) * 100
                if percentage >= self.MIN_PERCENTAGE:
                    valid_colors.append(colors_bgr[i])
                    valid_percentages.append(percentage)
            
            if not valid_colors:
                return self.analyze_colors_simple(pixels)
                
            merged_colors, merged_percentages = self._merge_similar_colors(valid_colors, valid_percentages)
            sorted_pairs = sorted(zip(merged_percentages, merged_colors), key=lambda x: x[0], reverse=True)
            
            if len(sorted_pairs) == 1 or sorted_pairs[0][0] > self.MONOCHROMATIC_THRESHOLD:
                return [{"bgr": sorted_pairs[0][1].astype(int).tolist(), "percentage": round(sorted_pairs[0][0], 2)}]
                
            return [{"bgr": color.astype(int).tolist(), "percentage": round(percentage, 2)} for percentage, color in sorted_pairs]
        except Exception as e:
            logger.debug(f"L·ªói ph√¢n t√≠ch m√†u n√¢ng cao: {e}")
            return self.analyze_colors_simple(pixels)

    def _analyze_limb_segment(self, image: np.ndarray, p1: tuple, p2: tuple, is_forearm: bool) -> Optional[List[Dict]]:
        """H√†m helper ƒë·ªÉ ph√¢n t√≠ch m√†u m·ªôt ƒëo·∫°n chi (tay/ch√¢n)."""
        if not self._is_valid_point(p1) or not self._is_valid_point(p2):
            return None
        pixels = self._get_pixels_from_line(image, p1, p2)
        if pixels is None:
            return None
        
        # C·∫≥ng tay ('forearm') c·∫ßn ph√¢n t√≠ch ƒëa m√†u ƒë·ªÉ c√≥ th·ªÉ ph√°t hi·ªán m√†u da
        if is_forearm:
            return self.analyze_colors_advanced(pixels)
        else: # C√°c b·ªô ph·∫≠n kh√°c ch·ªâ c·∫ßn m√†u ch·ªß ƒë·∫°o ƒë·ªÉ ph√¢n lo·∫°i qu·∫ßn/√°o
            colors = self.analyze_colors_advanced(pixels)
            return [max(colors, key=lambda x: x['percentage'])] if colors else None

    def _update_fps(self):
        """C·∫≠p nh·∫≠t t√≠nh to√°n FPS.""" 
        self.frame_count += 1
        current_time = asyncio.get_event_loop().time()
        elapsed_time = current_time - self.start_time
        if elapsed_time >= 1:
            self.fps = self.frame_count / elapsed_time
            logger.info(f"FPS POSE_COLOR: {self.fps:.2f}")
            self.start_time = current_time
            self.frame_count = 0


    # async def process_and_classify(
    #     self, 
    #     image: np.ndarray, 
    #     keypoints: np.ndarray,
    #     classifier: ClothingClassifier, 
    #     kpts_z: Optional[np.ndarray] = None,
    #     external_data: Optional[Dict] = None
    # ) -> Optional[Dict[str, Any]]:
    #     """
    #     Pipeline x·ª≠ l√Ω ph√¢n t√≠ch m√†u qu·∫ßn √°o (ƒê√£ v√° l·ªói NoneType).
    #     """
    #     print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh ph√¢n t√≠ch m√†u qu·∫ßn √°o...")
    #     # --- B∆Ø·ªöC QUAN TR·ªåNG: V√Å L·ªñI CRASH ---
    #     # Ki·ªÉm tra ·∫£nh ƒë·∫ßu v√†o
    #     if image is None or image.size == 0:
    #         return None
    #     if keypoints is None:
    #         return None 
    #     if external_data is None: external_data = {}
    #     print(f"Keypoints nh·∫≠n ƒë∆∞·ª£c: {keypoints}")
    #     try:
    #         # B∆Ø·ªöC 1: X√°c ƒë·ªãnh c√°c v√πng c∆° th·ªÉ
    #         # V√¨ ƒë√£ ki·ªÉm tra keypoints is None ·ªü tr√™n, c√°c h√†m d∆∞·ªõi n√†y s·∫Ω ch·∫°y an to√†n
    #         torso_box = HumanDetection.get_torso_box(keypoints)
    #         _arm_side, arm_coords = HumanDetection.select_best_arm(keypoints, kpts_z)
    #         _leg_side, leg_coords = HumanDetection.select_best_leg(keypoints, kpts_z)

    #         # B∆Ø·ªöC 2: Chu·∫©n b·ªã c√°c t√°c v·ª• (task) ƒë·ªÉ ch·∫°y b·∫•t ƒë·ªìng b·ªô
    #         tasks = {}

    #         # --- T√°c v·ª• cho Th√¢n (Torso) ---
    #         if torso_box:
    #             x1, y1, x2, y2 = torso_box
    #             # Ki·ªÉm tra t·ªça ƒë·ªô h·ª£p l·ªá
    #             if y2 > y1 and x2 > x1: 
    #                 torso_pixels = self._get_pixels_from_polygon(image, [(x1,y1), (x2,y1), (x2,y2), (x1,y2)])
    #                 tasks['torso'] = asyncio.to_thread(self.analyze_colors_advanced, torso_pixels)

    #         # --- T√°c v·ª• cho C√°nh tay (Arm) ---
    #         if arm_coords:
    #             p_shoulder = tuple(map(int, (arm_coords['shoulder']['x'], arm_coords['shoulder']['y'])))
    #             p_elbow = tuple(map(int, (arm_coords['elbow']['x'], arm_coords['elbow']['y'])))
    #             p_wrist = tuple(map(int, (arm_coords['wrist']['x'], arm_coords['wrist']['y'])))
    #             tasks['brachium'] = asyncio.to_thread(self._analyze_limb_segment, image, p_shoulder, p_elbow, False)
    #             tasks['forearm'] = asyncio.to_thread(self._analyze_limb_segment, image, p_elbow, p_wrist, True)

    #         # --- T√°c v·ª• cho Ch√¢n (Leg) ---
    #         if leg_coords:
    #             p_hip = tuple(map(int, (leg_coords['hip']['x'], leg_coords['hip']['y'])))
    #             p_knee = tuple(map(int, (leg_coords['knee']['x'], leg_coords['knee']['y'])))
    #             p_ankle = tuple(map(int, (leg_coords['ankle']['x'], leg_coords['ankle']['y'])))
    #             tasks['thigh'] = asyncio.to_thread(self._analyze_limb_segment, image, p_hip, p_knee, False)
    #             tasks['shin'] = asyncio.to_thread(self._analyze_limb_segment, image, p_knee, p_ankle, False)

    #         # B∆Ø·ªöC 3: Th·ª±c thi ƒë·ªìng th·ªùi c√°c t√°c v·ª•
    #         task_keys = list(tasks.keys())
    #         if not task_keys: 
    #             return None
            
    #         task_values = list(tasks.values())
    #         results = await asyncio.gather(*task_values, return_exceptions=True)

    #         # B∆Ø·ªöC 4: T·ªïng h·ª£p k·∫øt qu·∫£ m√†u s·∫Øc
    #         regional_analysis = {
    #             "torso_colors": None, "brachium_colors": None, "forearm_colors": None,
    #             "thigh_colors": None, "shin_colors": None
    #         }
    #         for i, key in enumerate(task_keys):
    #             result = results[i]
    #             if not isinstance(result, Exception):
    #                 regional_analysis[f"{key}_colors"] = result

    #         # B∆Ø·ªöC 5: G·ªçi classifier ƒë·ªÉ ph√¢n lo·∫°i lo·∫°i √°o/m√†u s·∫Øc
    #         data_for_classifier = {**external_data, "regional_analysis": regional_analysis, "image": image}
    #         classification_result = await asyncio.to_thread(classifier.classify, data_for_classifier)

    #         self._update_fps()
    #         # Tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng
    #         result = {
    #             "classification": classification_result, 
    #             "raw_color_data": regional_analysis,
    #             "processing_info": {
    #                 "k_clusters_default": self.k_clusters,
    #                 "best_arm_side": _arm_side,
    #                 "best_leg_side": _leg_side
    #             }
    #         }
    #         logger.info(f"Ph√¢n t√≠ch m√†u ho√†n t·∫•t: {result}")
    #         return result

    #     except Exception as e:
    #         logger.error(f"L·ªói pipeline ph√¢n t√≠ch m√†u: {e}", exc_info=True)
    #         return None
    # ƒë√£ s·ª≠a 
    async def process_and_classify(
        self, 
        image: np.ndarray, 
        keypoints: np.ndarray,
        classifier: ClothingClassifier, 
        kpts_z: Optional[np.ndarray] = None,
        external_data: Optional[Dict] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Pipeline x·ª≠ l√Ω ph√¢n t√≠ch m√†u qu·∫ßn √°o (ƒê√£ v√° l·ªói NoneType).
        """
        print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh ph√¢n t√≠ch m√†u qu·∫ßn √°o...")
        # --- B∆Ø·ªöC QUAN TR·ªåNG: V√Å L·ªñI CRASH ---
        # Ki·ªÉm tra ·∫£nh ƒë·∫ßu v√†o
        if image is None or image.size == 0:
            return None
        if keypoints is None:
            return None 
        if external_data is None: external_data = {}

        # ‚îÄ‚îÄ‚îÄ DEBUG QUAN TR·ªåNG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # logger.info(f"[PoseColor DEBUG] Keypoints shape: {keypoints.shape if keypoints is not None else 'None'}")
        # logger.info(f"[PoseColor DEBUG] C√≥ {len(keypoints) if keypoints is not None else 0} keypoints")

        torso_box = HumanDetection.get_torso_box(keypoints)
        # logger.info(f"[PoseColor DEBUG] Torso box: {torso_box}")

        arm_side, arm_coords = HumanDetection.select_best_arm(keypoints, kpts_z)
        # logger.info(f"[PoseColor DEBUG] Best arm side: {arm_side} | coords: {arm_coords}")

        leg_side, leg_coords = HumanDetection.select_best_leg(keypoints, kpts_z)
        # logger.info(f"[PoseColor DEBUG] Best leg side: {leg_side} | coords: {leg_coords}")

        # ... ph·∫ßn c√≤n l·∫°i gi·ªØ nguy√™n  
        
        try:
            timestamp = time.strftime("%Y%m%d_%H%M%S_%f")[:-3]
            person_id = external_data.get('person_id', 'unknown')
            
            # üî• S·ª¨A: D√πng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·ªÉ tr√°nh l·ªói kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c
            # L·∫•y th∆∞ m·ª•c hi·ªán t·∫°i c·ªßa project
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) 
            # Ho·∫∑c d√πng os.getcwd() n·∫øu ch·∫°y t·ª´ root
            
           # save_dir = os.path.join(os.getcwd(), 'debug_body') # L∆∞u ngay t·∫°i th∆∞ m·ª•c ch·∫°y l·ªánh
            
            # if not os.path.exists(save_dir):
            #     os.makedirs(save_dir, exist_ok=True)
            
            # debug_filename = f"body_{timestamp}_id{person_id}.jpg"
            # debug_path = os.path.join(save_dir, debug_filename)
            
            # # L∆∞u ·∫£nh
            # success = cv2.imwrite(debug_path, image, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            # if success:
            #     logger.info(f"[DEBUG BODY] ƒê√£ l∆∞u: {debug_path}")
            # else:
            #     # In ra l√Ω do c·ª• th·ªÉ h∆°n (v√≠ d·ª• image r·ªóng)
            #     if image is None or image.size == 0:
            #          logger.error(f"[DEBUG BODY] L∆∞u th·∫•t b·∫°i: ·∫¢nh r·ªóng!")
            #     else:
            #          logger.error(f"[DEBUG BODY] L∆∞u th·∫•t b·∫°i (Check quy·ªÅn folder): {debug_path}")
                
            # B∆Ø·ªöC 5: G·ªçi classifier ƒë·ªÉ ph√¢n lo·∫°i lo·∫°i √°o/m√†u s·∫Øc
            torso_box = HumanDetection.get_torso_box(keypoints)
            _arm_side, arm_coords = HumanDetection.select_best_arm(keypoints, kpts_z)
            _leg_side, leg_coords = HumanDetection.select_best_leg(keypoints, kpts_z)

            # B∆Ø·ªöC 2: Chu·∫©n b·ªã c√°c t√°c v·ª• (task) ƒë·ªÉ ch·∫°y b·∫•t ƒë·ªìng b·ªô
            tasks = {}

            # --- T√°c v·ª• cho Th√¢n (Torso) ---
            if torso_box:
                x1, y1, x2, y2 = torso_box
                # Ki·ªÉm tra t·ªça ƒë·ªô h·ª£p l·ªá
                if y2 > y1 and x2 > x1: 
                    torso_pixels = self._get_pixels_from_polygon(image, [(x1,y1), (x2,y1), (x2,y2), (x1,y2)])
                    tasks['torso'] = asyncio.to_thread(self.analyze_colors_advanced, torso_pixels)

            # --- T√°c v·ª• cho C√°nh tay (Arm) ---
            if arm_coords:
                p_shoulder = tuple(map(int, (arm_coords['shoulder']['x'], arm_coords['shoulder']['y'])))
                p_elbow = tuple(map(int, (arm_coords['elbow']['x'], arm_coords['elbow']['y'])))
                p_wrist = tuple(map(int, (arm_coords['wrist']['x'], arm_coords['wrist']['y'])))
                tasks['brachium'] = asyncio.to_thread(self._analyze_limb_segment, image, p_shoulder, p_elbow, False)
                tasks['forearm'] = asyncio.to_thread(self._analyze_limb_segment, image, p_elbow, p_wrist, True)

            # --- T√°c v·ª• cho Ch√¢n (Leg) ---
            if leg_coords:
                p_hip = tuple(map(int, (leg_coords['hip']['x'], leg_coords['hip']['y'])))
                p_knee = tuple(map(int, (leg_coords['knee']['x'], leg_coords['knee']['y'])))
                p_ankle = tuple(map(int, (leg_coords['ankle']['x'], leg_coords['ankle']['y'])))
                tasks['thigh'] = asyncio.to_thread(self._analyze_limb_segment, image, p_hip, p_knee, False)
                tasks['shin'] = asyncio.to_thread(self._analyze_limb_segment, image, p_knee, p_ankle, False)

            # B∆Ø·ªöC 3: Th·ª±c thi ƒë·ªìng th·ªùi c√°c t√°c v·ª•
            task_keys = list(tasks.keys())
            if not task_keys: 
                return None
            
            task_values = list(tasks.values())
            results = await asyncio.gather(*task_values, return_exceptions=True)

            # B∆Ø·ªöC 4: T·ªïng h·ª£p k·∫øt qu·∫£ m√†u s·∫Øc
            regional_analysis = {
                "torso_colors": [], 
                "brachium_colors": [], 
                "forearm_colors": [], 
                "thigh_colors": [], 
                "shin_colors": []
            }

            for i, key in enumerate(task_keys):
                result = results[i]
                if not isinstance(result, Exception) and result is not None:
                    regional_analysis[f"{key}_colors"] = result

            # √âp t·∫•t c·∫£ th√†nh list r·ªóng n·∫øu None (fix g·ªëc r·ªÖ)
            for k in regional_analysis:
                if regional_analysis[k] is None or not isinstance(regional_analysis[k], list):
                    regional_analysis[k] = []
            
            # B∆Ø·ªöC 5: G·ªçi classifier ƒë·ªÉ ph√¢n lo·∫°i lo·∫°i √°o/m√†u s·∫Øc
            data_for_classifier = {**external_data, "regional_analysis": regional_analysis, "image": image}
            classification_result = await asyncio.to_thread(classifier.classify, data_for_classifier)

            self._update_fps()
            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng
            result = {
                "classification": classification_result, 
                "raw_color_data": regional_analysis,
                "processing_info": {
                    "k_clusters_default": self.k_clusters,
                    "best_arm_side": _arm_side,
                    "best_leg_side": _leg_side
                }
            }           
            logger.info(f"Ph√¢n t√≠ch m√†u ho√†n t·∫•t: {result}")
            return result

        except Exception as e:
            logger.error(f"L·ªói pipeline ph√¢n t√≠ch m√†u: {e}", exc_info=True)
            return None

def create_analyzer(line_thickness: int = 30, k_clusters: int = 3) -> PoseColorAnalyzer:
    """Factory function ƒë·ªÉ t·∫°o analyzer v·ªõi config m·∫∑c ƒë·ªãnh."""
    return PoseColorAnalyzer(line_thickness=line_thickness, k_clusters=k_clusters)