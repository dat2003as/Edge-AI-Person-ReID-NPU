# core/tracker/manager.py - COMPLETE FILE
import os
import queue
import threading
import time
from collections import deque

import cv2
import config
from .utils import TrackerUtils
from .consolidation import AttributeConsolidator
from .matching import ConfirmedPersonMatcher
import logging
import numpy as np
from utils.focus_quality_checker import FocusQualityChecker

logger = logging.getLogger(__name__)

DEBUG_FOLDER = "debug_aligned"
SAVE_DEBUG_IMAGES = True

if SAVE_DEBUG_IMAGES and not os.path.exists(DEBUG_FOLDER):
    os.makedirs(DEBUG_FOLDER)

class TrackManager:
    """
    üî• FIXED VERSION v·ªõi Focus Quality Gating
    - Ch·ªâ ch·ªët ID khi camera l·∫•y n√©t t·ªët
    - X√≥a duplicate code
    - L∆∞u body_crop ƒë·∫ßy ƒë·ªß
    """

    def __init__(self, analyzer, db_manager, dual_stream_manager=None, llm_sender=None):
        self.analyzer = analyzer
        self.db_manager = db_manager
        self.consolidator = AttributeConsolidator(db_manager)
        self.matcher = ConfirmedPersonMatcher(db_manager)
        
        # LLM Integration
        self.dual_stream_manager = dual_stream_manager
        self.llm_sender = llm_sender
        
        # üî• Focus Quality Checker
        self.focus_checker = FocusQualityChecker(
            min_face_sharpness=120,
            min_body_sharpness=80,
            min_face_size=80,
            min_body_area=30000
        )
        
        self.cancelled_ids = set()
        self.tracked_objects = {}
        self.next_person_id = 1
        self.id_lock = threading.Lock()
        
        self.global_frame_count = 0
        self.last_queue_clear_frame = 0
    
    def _identify_or_register(self, track_id):
        """
        üî• IMPROVED: Them rematch check truoc khi search DB
        - Kiem tra confirmed persons da thay trong 5 giay gan do
        - Chi search DB neu rematch that bai
        """
        if track_id not in self.tracked_objects: 
            return

        obj_data = self.tracked_objects[track_id]
        current_final_id = obj_data.get('final_id', '')

        # ============================================================
        # B∆Ø·ªöC 0: DEADLOCK CHECK
        # ============================================================
        if obj_data['status'] == 'confirmed' and not current_final_id.startswith('Temp_'):
            return
        
        history = obj_data.get('history_attributes', [])
        if len(history) == 0:
            return
        
        # ============================================================
        # B∆Ø·ªöC 0.5: CHECK CONFIRMED PERSON REMATCH (NEW)
        # ============================================================
        bbox = obj_data.get('bbox', [0, 0, 100, 100])
        reid_query = TrackerUtils.get_query_vector(obj_data['reid_vectors'])
        face_query = TrackerUtils.get_query_vector_face(obj_data['face_vectors'])
        final_attrs = obj_data.get('final_attributes', {})
        
        rematch_result = self.matcher.check_confirmed_person_rematch(
            track_id=track_id,
            bbox=bbox,
            face_vector=face_query,
            reid_vector=reid_query,
            current_attributes=final_attrs
        )
        
        if rematch_result:
            # Tim thay confirmed person cu
            final_id, rematch_score, rematch_source = rematch_result
            obj_data.update({
                'final_id': final_id,
                'identification_source': rematch_source,
                'status': 'identified'
            })
            
            logger.info(
                f"‚úÖ [REMATCH CONFIRMED] Track {track_id} ‚Üí {final_id} "
                f"({rematch_source}) Score: {rematch_score:.4f}"
            )
            
            # Luu vector ReID
            if list(obj_data['reid_vectors']):
                self.db_manager.add_vectors(config.REID_NAMESPACE, final_id, list(obj_data['reid_vectors']))
                self.db_manager.save_all_databases()
            
            self.consolidator.consolidate(obj_data)
            return  # Dung lai, khong can search DB
        
        # ============================================================
        # B∆Ø·ªöC 0.6: CHECK LLM PROCESSING (NEW)
        # ============================================================
        # Neu rematch thanh cong, kiem tra xem co can gui LLM khong
        if rematch_result:
            final_id = rematch_result[0]
            need_llm, duration, reason = self.matcher.check_llm_processing_needed(final_id)
            
            if need_llm and self.llm_sender and self.dual_stream_manager:
                # Lay metadata day du
                metadata = self.db_manager.get_metadata(final_id)
                
                # Chu·∫©n b·ªã data cho LLM
                llm_data = {
                    'person_id': final_id,
                    'duration_minutes': duration,
                    'first_seen': metadata.get('first_seen_time'),
                    'last_seen': metadata.get('last_seen_time'),
                    'attributes': {
                        'gender': metadata.get('confirmed_gender', 'unknown'),
                        'age': metadata.get('confirmed_age', 'unknown'),
                        'race': metadata.get('confirmed_race', 'unknown')
                    },
                    'context': 'long_absence',
                    'reason': reason
                }
                
                logger.warning(
                    f"ü§ñ [LLM SEND] {final_id} - Duration: {duration:.1f} min\n"
                    f"   Reason: {reason}\n"
                    f"   Attributes: {llm_data['attributes']}\n"
                    f"   ‚Üí Sending to LLM for processing"
                )
                
                # G·ª≠i qua dual_stream_manager
                try:
                    # Goi send_long_absence thong qua dual_stream_manager
                    if hasattr(self.dual_stream_manager, 'send_long_absence_notification'):
                        self.dual_stream_manager.send_long_absence_notification(
                            person_id=final_id,
                            duration_minutes=duration,
                            metadata=llm_data,
                            llm_sender=self.llm_sender
                        )
                    else:
                        # Fallback: goi truc tiep llm_sender
                        if hasattr(self.llm_sender, 'send_custom_message'):
                            message = (
                                f"Person {final_id} returned after {duration:.1f} minutes.\n"
                                f"Gender: {llm_data['attributes']['gender']}, "
                                f"Age: {llm_data['attributes']['age']}, "
                                f"Race: {llm_data['attributes']['race']}"
                            )
                            self.llm_sender.send_custom_message(message)
                    
                    logger.info(f"‚úÖ [LLM SENT] Successfully sent {final_id} to LLM")
                    
                except Exception as e:
                    logger.error(f"‚ùå [LLM ERROR] Failed to send {final_id}: {e}")
        
        # ============================================================
        # B∆Ø·ªöC 1: FALLBACK SEARCH DB (neu rematch that bai)
        # ============================================================
        # LOGIC: Neu rematch fail nhung co face vector, vay search DB
        # voi logic nhu sau:
        # - Neu search DB tim thay ‚Üí co the la confirmed person khac
        #   hoac nguoi toan toan moi
        # - Neu search DB khong tim thay ‚Üí tao ID moi
        
        if face_query is None and reid_query is None: 
            return

        # Log rematch failure reason
        logger.info(
            f"‚è≥ [REMATCH SKIP] Track {track_id} - Spatial/Temporal not match, "
            f"fallback to DB search"
        )

        face_match = self.db_manager.search_vector_with_voting(
            config.FACE_NAMESPACE, face_query
        ) if face_query else None
        
        reid_match = self.db_manager.search_vector_with_voting(
            config.REID_NAMESPACE, reid_query
        ) if reid_query else None

        logger.info(f"üîç [DB SEARCH RESULT] Track {track_id}: Face={face_match} | ReID={reid_match}")
        
        f_id, f_score = face_match if face_match else (None, 0.0)
        r_id, r_score = reid_match if reid_match else (None, 0.0)

        # ============================================================
        # B∆Ø·ªöC 2: ADAPTIVE THRESHOLD
        # ============================================================
        bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
        
        dynamic_threshold = 0.50
        if bbox_area > 80000: dynamic_threshold = 0.60
        elif len(history) > 15: dynamic_threshold = 0.48
        elif bbox_area < 30000: dynamic_threshold = 0.45

        # ============================================================
        # B∆Ø·ªöC 3: QUY·∫æT ƒê·ªäNH ID - üî• FACE PRIORITY (Face unique h∆°n qu·∫ßn √°o)
        # ============================================================
        final_id, final_score, final_source = None, 0.0, ""

        # üî• B∆Ø·ªöC 3A: FACE H·ª¢P NH·∫§T (C·∫£ Face v√† ReID c√πng agree)
        if f_id == r_id and f_id is not None:
            final_id, final_score, final_source = f_id, max(f_score, r_score), "H·ª¢P NH·∫§T (FACE+REID)"

        # üî• B∆Ø·ªöC 3B: FACE PRIORITY - N·∫øu Face match tin c·∫≠y ‚Üí d√πng Face
        # (V√¨ Face kh√¥ng thay ƒë·ªïi khi pose/angle/ƒë·ªì thay ƒë·ªïi)
        elif f_id and f_score > 0.65:
            final_id, final_score, final_source = f_id, f_score, "M·∫∂T (PRIORITY)"
            
            # ‚ö†Ô∏è Log n·∫øu ReID suggest ng∆∞·ªùi kh√°c (c√≥ th·ªÉ pose/angle kh√°c)
            if r_id and r_id != f_id and r_score > 0.75:
                logger.warning(
                    f"‚ö†Ô∏è [FACE OVERRIDE] Track {track_id}: "
                    f"Face={f_id} (score={f_score:.4f}), "
                    f"but ReID={r_id} (score={r_score:.4f}). "
                    f"Using FACE (more reliable than ReID)"
                )

        # üî• B∆Ø·ªöC 3C: FALLBACK ReID (Khi kh√¥ng c√≥ Face match tin c·∫≠y)
        elif r_score > 0.80:
            final_id, final_score, final_source = r_id, r_score, "TO√ÄN TH√ÇN (VERY HIGH)"
        elif r_score > 0.60:
            final_id, final_score, final_source = r_id, r_score, "TO√ÄN TH√ÇN (HIGH)"
        elif r_score > dynamic_threshold:
            final_id, final_score, final_source = r_id, r_score, "TO√ÄN TH√ÇN (MODERATE)"
        elif r_id:
            final_id, final_score, final_source = r_id, r_score, "TO√ÄN TH√ÇN (LOW)"

        # ============================================================
        # B∆Ø·ªöC 4: C·∫¨P NH·∫¨T STATUS
        # ============================================================
        if final_id:
            # ‚úÖ T√åM TH·∫§Y NG∆Ø·ªúI C≈®
            obj_data.update({
                'final_id': final_id,
                'identification_source': final_source,
                'status': 'identified'
            })
            
            logger.info(f"‚úÖ [MATCHED] Track {track_id} ‚Üí {final_id} ({final_source}) Score: {final_score:.4f}")
            
            # Luu vector ReID
            if list(obj_data['reid_vectors']):
                self.db_manager.add_vectors(config.REID_NAMESPACE, final_id, list(obj_data['reid_vectors']))
                self.db_manager.save_all_databases()
            
            # Goi consolidator
            logger.info(f"üîÑ [CONSOLIDATE] Calling for matched person: {final_id}")
            self.consolidator.consolidate(obj_data)
        
        else:
            # ‚úÖ T·∫†O PROFILE M·ªöI (Person_X)
            valid_frames = len(history)
            
            if bbox_area > config.MIN_BBOX_AREA and valid_frames >= 2: 
                with self.id_lock:
                    new_id = f"Person_{self.next_person_id}"
                    self.next_person_id += 1
                
                # üî• LU√îN SET 'identified', ƒê·ªÇ CONSOLIDATOR QUY·∫æT ƒê·ªäNH 'confirmed'
                obj_data.update({
                    'final_id': new_id, 
                    'status': 'identified'  # Consolidator s·∫Ω chuy·ªÉn l√™n 'confirmed' khi ƒë·ªß attributes
                })
                
                logger.info(
                    f"üÜï [NEW PROFILE] Track {track_id} ‚Üí {new_id} "
                    f"(Frames: {valid_frames}, Area: {bbox_area}) | Status: identified"
                )                
                
                # L∆∞u vector ReID
                if list(obj_data['reid_vectors']):
                    self.db_manager.add_vectors(config.REID_NAMESPACE, new_id, list(obj_data['reid_vectors']))
                    self.db_manager.save_all_databases()
                
                # üî• G·ªåI CONSOLIDATOR CHO NG∆Ø·ªúI M·ªöI
                logger.info(f"üîÑ [CONSOLIDATE] Calling for new person: {new_id}")
                self.consolidator.consolidate(obj_data)
            
            else:
                logger.debug(f"‚è≥ [WAITING] Track {track_id} needs more data")



    def process_attribute_results(self, attribute_result_queue):
        """
        üî• TRIGGER ID NGAY KHI C√ì ƒê·ª¶ D·ªÆ LI·ªÜU
        """
        if attribute_result_queue.empty():
            return
        
        while not attribute_result_queue.empty():
            track_id, analysis_result = attribute_result_queue.get()
            
            if track_id not in self.tracked_objects or not analysis_result: 
                continue
            
            if analysis_result.get('status') == 'skipped_blur':
                continue

            obj_data = self.tracked_objects[track_id]
            person_id = obj_data.get('final_id', f"Track_{track_id}")

            # ============================================================
            # B∆Ø·ªöC 1: APPEND HISTORY
            # ============================================================
            obj_data['history_attributes'].append(analysis_result)
            
            print(f"‚úÖ [APPEND] Track {track_id} | History len: {len(obj_data['history_attributes'])}")
            
            # üî• CONSOLIDATE NGAY SAU KHI APPEND
            print(f"üîÑ [CALLING CONSOLIDATE] For {person_id}")
            self.consolidator.consolidate(obj_data)
            
            # ============================================================
            # B∆Ø·ªöC 2: L∆ØU VECTORS
            # ============================================================
            face_vec = analysis_result.get('face_vector')
            reid_vec = analysis_result.get('reid_vector')
            
            if obj_data['status'] in ['pending', 'tentative']:
                if reid_vec and isinstance(reid_vec, np.ndarray):
                    obj_data['reid_vectors'].append(reid_vec)
                    print(f"   ‚Üí ReID vectors: {len(obj_data['reid_vectors'])}")
                
                if face_vec:
                    face_conf = analysis_result.get('face_conf', 0)
                    if face_conf >= 0.5:
                        obj_data['face_vectors'].append((face_vec, face_conf))
                        print(f"   ‚Üí Face vectors: {len(obj_data['face_vectors'])}")

            # ============================================================
            # üî• B∆Ø·ªöC 3: TRIGGER ID - CHO PH√âP RE-IDENTIFY (WITH THROTTLING)
            # ============================================================
            # üî• FIX: Cho ph√©p g·ªçi identify c·∫£ khi status='identified'
            # ƒë·ªÉ c√≥ c∆° h·ªôi chuy·ªÉn l√™n 'confirmed'
            # üî• THROTTLE: Ch·ªâ g·ªçi m·ªói 30 frames ƒë·ªÉ tr√°nh spam DB queries
            if obj_data['status'] in ['pending', 'identified']:
                history_len = len(obj_data['history_attributes'])
                has_vectors = len(obj_data['reid_vectors']) > 0 or len(obj_data['face_vectors']) > 0
                
                # Initialize last_identify_frame if not exists
                if 'last_identify_frame' not in obj_data:
                    obj_data['last_identify_frame'] = 0
                    logger.info(f"üÜï [THROTTLE INIT] {person_id} - Initialized last_identify_frame=0")
                
                frames_since_last_id = self.global_frame_count - obj_data['last_identify_frame']
                should_try_identify = False
                
                logger.info(
                    f"üîç [CHECK TRIGGER] {person_id} | "
                    f"History: {history_len} | Vectors: {has_vectors} | "
                    f"Status: {obj_data['status']} | "
                    f"Global Frame: {self.global_frame_count} | "
                    f"Last ID Frame: {obj_data['last_identify_frame']} | "
                    f"Frames since ID: {frames_since_last_id}"
                )
                
                # üî• ƒêI·ªÄU KI·ªÜN 1: C√≥ ‚â• 1 frames + c√≥ vectors
                if history_len >= 1 and has_vectors:
                    # First time or throttled retry
                    if obj_data['last_identify_frame'] == 0:
                        should_try_identify = True
                        logger.warning(f"üéØ [FIRST IDENTIFY] Track {track_id} - First time!")
                    elif frames_since_last_id >= 30:
                        should_try_identify = True
                        logger.warning(f"üéØ [RETRY IDENTIFY] Track {track_id} - Retry after {frames_since_last_id} frames")
                    else:
                        logger.warning(f"‚è≠Ô∏è [THROTTLE SKIP] {person_id} - Waiting {30 - frames_since_last_id} more frames")
                
                # üî• ƒêI·ªÄU KI·ªÜN 2: C√≥ ‚â• 3 frames (fallback)
                elif history_len >= 2:
                    if obj_data['last_identify_frame'] == 0:
                        should_try_identify = True
                        logger.warning(f"üéØ [FIRST IDENTIFY FALLBACK] Track {track_id}")
                    elif frames_since_last_id >= 30:
                        should_try_identify = True
                        logger.warning(f"üéØ [RETRY IDENTIFY FALLBACK] Track {track_id} - After {frames_since_last_id} frames")
                    else:
                        logger.warning(f"‚è≠Ô∏è [THROTTLE SKIP FALLBACK] {person_id} - Waiting {30 - frames_since_last_id} more frames")
                else:
                    logger.info(f"   ‚è≥ [WAITING] {person_id} - Need more data (history={history_len}, vectors={has_vectors})")
                
                # Execute identification if allowed
                if should_try_identify:
                    logger.warning(f"üöÄ [EXECUTING IDENTIFY] {person_id} at frame {self.global_frame_count}")
                    obj_data['last_identify_frame'] = self.global_frame_count
                    self._identify_or_register(track_id)
                    logger.warning(f"‚úÖ [IDENTIFY DONE] {person_id} - Updated last_identify_frame to {self.global_frame_count}")

            # ============================================================
            # B∆Ø·ªöC 4: L∆ØU VECTORS V√ÄO DB (CH·ªà IDENTIFIED+)
            # ============================================================
            if not person_id.startswith("Temp_"):
                # Save face vectors to DB
                if face_vec is not None and obj_data.get('status') in ['identified', 'confirmed']:
                    face_count = self.db_manager.count_vectors_for_id(config.FACE_NAMESPACE, person_id)
                    if face_count < config.MAX_FACE_VECTORS_PER_PROFILE:
                        self.db_manager.add_vectors(config.FACE_NAMESPACE, person_id, [face_vec])
                        print(f"   üíæ [DB] Saved face vector for {person_id} ({face_count+1}/{config.MAX_FACE_VECTORS_PER_PROFILE})")

            # ============================================================
            # B∆Ø·ªöC 5: CONSOLIDATE
            # ============================================================
            self.consolidator.consolidate(obj_data)
            
            # ============================================================
            # B∆Ø·ªöC 6: L∆ØU CONFIRMED ATTRIBUTES (immutable)
            # ============================================================
            # Neu status vua chuyen thanh 'confirmed', luu attributes bat bien
            if obj_data['status'] == 'confirmed' and not person_id.startswith("Temp_"):
                # Kiem tra xem attributes co thay doi khong
                # (Neu co thay doi thi khong luu - chi luu lan dau tien khi confirm)
                meta = self.db_manager.get_metadata(person_id)
                if 'confirmed_gender' not in meta:
                    # Lan dau tien confirmed -> luu bat bien
                    self.matcher.save_confirmed_attributes(person_id, obj_data)
                    # Lay lai metadata sau khi save de lay confirmed_name
                    meta = self.db_manager.get_metadata(person_id)
                    confirmed_name = meta.get('confirmed_name', 'Unknown')
                    logger.info(f"‚úÖ [CONFIRMED] {person_id} - {confirmed_name} - Saved immutable attributes to DB")
                else:
                    # Da luu roi, chi update last_seen (khong can bbox)
                    meta['last_seen_time'] = __import__('datetime').datetime.now().isoformat()
                    self.db_manager.update_metadata(person_id, meta)
                    confirmed_name = meta.get('confirmed_name', 'Unknown')
                    logger.debug(f"üîÑ [UPDATE] {person_id} - {confirmed_name} - Updated last_seen")


    def update_tracks(self, track_ids, bboxes, frame, attribute_task_queue, frame_original=None, scale_x=1.0, scale_y=1.0):
        """
        üî• FULLY FIXED v·ªõi Frame Skip Controller integration + High Res Support
        """
        self.global_frame_count += 1
        current_track_ids = set(track_ids)
        current_time = time.time()
        
        # ============================================================
        # KH√îNG C√ì NG∆Ø·ªúI ‚Üí X√ìA QUEUE
        # ============================================================
        if len(track_ids) == 0:
            if attribute_task_queue is not None:
                cleared_count = 0
                try:
                    while not attribute_task_queue.empty():
                        attribute_task_queue.get_nowait()
                        cleared_count += 1
                except:
                    pass
                
                if cleared_count > 0 and (self.global_frame_count - self.last_queue_clear_frame) > 30:
                    logger.info(f"üóëÔ∏è [QUEUE] ƒê√£ x√≥a {cleared_count} tasks v√¨ kh√¥ng c√≤n ng∆∞·ªùi")
                    self.last_queue_clear_frame = self.global_frame_count
            return
        
        # ============================================================
        # PROCESSING TRACKS
        # ============================================================
        for i, track_id in enumerate(track_ids):
            bbox = bboxes[i]
            
            if track_id not in self.tracked_objects:
                logger.info(f"‚ú® [ID: {track_id}] Track m·ªõi.")
                self.tracked_objects[track_id] = {
                    'status': 'pending', 
                    'final_id': f"Temp_{track_id}", 
                    'bbox': bbox,
                    'reid_vectors': deque(maxlen=config.MOVING_AVERAGE_WINDOW),
                    'face_vectors': deque(maxlen=config.MOVING_AVERAGE_WINDOW),
                    'disappeared_frames': 0, 
                    'quality_score': 0.0,
                    'history_attributes': deque(maxlen=30),
                    'final_attributes': None,
                    'frames_since_last_attr_analysis': 4,
                    'last_analysis_frame': 0
                }
            
            obj_data = self.tracked_objects[track_id]
            obj_data['bbox'] = bbox
            obj_data['disappeared_frames'] = 0
            obj_data['frames_since_last_attr_analysis'] += 1
            
            should_send_task = False
            
            # HYBRID MODE THROTTLE LOGIC
            current_status = obj_data['status']
            
            if current_status == 'pending':
                # PENDING: Skip every 5 frames @ 24 FPS = ~5 FPS effective (SMOOTH)
                if obj_data['frames_since_last_attr_analysis'] >= 2:
                    should_send_task = True
                    throttle_mode = "SMOOTH (every 5 frames, ~5 FPS)"
                else:
                    should_send_task = False
                    throttle_mode = f"SKIP (waiting {5 - obj_data['frames_since_last_attr_analysis']} more)"

                
            elif current_status == 'identified':
                # IDENTIFIED: Skip every 5 frames @ 24 FPS = ~5 FPS effective (SMOOTH)
                if obj_data['frames_since_last_attr_analysis'] >= 5:
                    should_send_task = True
                    throttle_mode = "SMOOTH (every 5 frames, ~5 FPS)"
                else:
                    should_send_task = False
                    throttle_mode = f"SKIP (waiting {5 - obj_data['frames_since_last_attr_analysis']} more)"
                    
            elif current_status == 'confirmed':
                # üî• CONFIRMED: M·ªói 5 frames (1s) - LIGHT update cho 5 FPS
                # Ho·∫∑c SKIP ho√†n to√†n n·∫øu b·∫°n ch·ªçn Option 1
                if obj_data['frames_since_last_attr_analysis'] >= 2:
                    should_send_task = True
                    throttle_mode = "LIGHT (every 5 frames, 5fps)"
                else:
                    throttle_mode = f"LIGHT (waiting {5 - obj_data['frames_since_last_attr_analysis']} more)"
            else:
                # Fallback cho tentative hoac status khac
                if obj_data['frames_since_last_attr_analysis'] >= 1:
                    should_send_task = True
                    throttle_mode = "FALLBACK (every frame)"
                else:
                    throttle_mode = "FALLBACK (waiting)"
            
            # Logging r√µ r√†ng (m·ªói 10 frames ƒë·ªÉ th·∫•y skip behavior)
            if self.global_frame_count % 10 == 0 or not should_send_task:
                person_id = obj_data.get('final_id', f"Track_{track_id}")
                skip_indicator = "‚è≠Ô∏è [SKIP]" if not should_send_task else "‚úÖ [SEND]"
                logger.info(
                    f"{skip_indicator} {person_id} | Status: {current_status} | "
                    f"Mode: {throttle_mode} | Frames since last: {obj_data['frames_since_last_attr_analysis']}"
                )

            # ============================================================
            # üî• G·ª¨I TASK V·ªöI FRAME SKIP LOGIC
            # ============================================================
            if should_send_task and attribute_task_queue is not None:
                current_queue_size = attribute_task_queue.qsize()
                
                # üî• T√çNH BBOX AREA
                x1, y1, x2, y2 = bbox
                bbox_area = (x2 - x1) * (y2 - y1) 

                if current_queue_size > 15:
                    if self.global_frame_count % 10 == 0:
                        logger.warning(f"‚è≠Ô∏è [SKIP] Queue qu√° ƒë·∫ßy ({current_queue_size}), skip frame")
                    continue
                   
                # üî• KI·ªÇM TRA FRAME SKIP CONTROLLER
                if hasattr(self, 'frame_skip_controller'):
                    if not self.frame_skip_controller.should_process_frame(
                        track_id=track_id,
                        bbox_area=bbox_area,
                        queue_size=current_queue_size
                    ):
                        continue  # Skip frame n√†y
                
                # CHECK FULLY LOCKED
                target_id = obj_data.get('final_id', f"Temp_{track_id}")
                
                if hasattr(self, 'dual_stream_manager'):
                    if self.dual_stream_manager.is_fully_locked(target_id):
                        if self.global_frame_count % 30 == 0:
                            logger.info(f"‚è≠Ô∏è [SKIP] {target_id} ƒë√£ fully locked")
                        continue
                
                # üî• T·∫†O TASK DATA V·ªöI FULL RESOLUTION SUPPORT
                
                # 1. T√≠nh to√°n bbox tr√™n frame g·ªëc 2K (n·∫øu c√≥)
                bbox_original = bbox  # M·∫∑c ƒë·ªãnh d√πng bbox resized n·∫øu kh√¥ng c√≥ frame g·ªëc
                frame_for_face = frame.copy() # M·∫∑c ƒë·ªãnh d√πng frame resized

                if frame_original is not None:
                    # Scale bbox t·ª´ 640x480 -> 2K
                    bx1 = int(x1 * scale_x)
                    by1 = int(y1 * scale_y)
                    bx2 = int(x2 * scale_x)
                    by2 = int(y2 * scale_y)
                    
                    # Clamp coordinates
                    h_orig, w_orig = frame_original.shape[:2]
                    bx1 = max(0, min(bx1, w_orig))
                    by1 = max(0, min(by1, h_orig))
                    bx2 = max(0, min(bx2, w_orig))
                    by2 = max(0, min(by2, h_orig))
                    
                    bbox_original = [bx1, by1, bx2, by2]
                    frame_for_face = frame_original # üî• Quan tr·ªçng: Pass reference (copy t·ªën RAM, worker s·∫Ω copy n·∫øu c·∫ßn)
                
                task_data = {
                    'track_id': track_id,
                    'frame_resized': frame.copy(),          # 640x480: D√πng cho Pose, Clothing (nh·∫π)
                    'frame_original': frame_for_face,       # 2K: D√πng cho Face (ch·∫•t l∆∞·ª£ng cao)
                    'bbox_resized': bbox,                   # bbox 640x480
                    'bbox_original': bbox_original,         # bbox 2K
                    'person_id': target_id,
                    'confirmed_status': obj_data['status'],
                    'created_at_frame': self.global_frame_count,
                    'timestamp': current_time
                }
                
                try:
                    attribute_task_queue.put_nowait(task_data)
                    obj_data['frames_since_last_attr_analysis'] = 0
                    obj_data['last_analysis_frame'] = self.global_frame_count
                except queue.Full:
                    if self.global_frame_count % 30 == 0:
                        logger.warning(f"‚ö†Ô∏è [QUEUE] Kh√¥ng th·ªÉ g·ª≠i task, queue ƒë·∫ßy")

        # ============================================================
        # CLEANUP DISAPPEARED TRACKS
        # ============================================================
        disappeared_ids = set(self.tracked_objects.keys()) - current_track_ids
        for track_id in disappeared_ids:
            self.tracked_objects[track_id]['disappeared_frames'] += 1

        max_frames = 5 if len(current_track_ids) == 0 else config.MAX_DISAPPEARED_FRAMES

        cleanup_ids = [
            tid for tid, data in self.tracked_objects.items() 
            if data['disappeared_frames'] > max_frames
        ]

        for tid in cleanup_ids:
            person_id = self.tracked_objects[tid].get('final_id', f"Temp_{tid}")
            logger.info(
                f"üóëÔ∏è [CLEANUP] ƒê√£ x√≥a track {tid} ({person_id}) "
                f"sau {self.tracked_objects[tid]['disappeared_frames']} frames"
            )
            del self.tracked_objects[tid]
            
            if not person_id.startswith("Temp_"):
                self.db_manager.save_all_databases()